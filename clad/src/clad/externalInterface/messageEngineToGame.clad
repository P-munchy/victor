// UiMessageDefinitions message definition file
//  for the C-Like Abstract Data language
// Author: Greg Nagel
// Copyright: Anki Inc (c) 2015

#include "clad/types/actionTypes.clad"
#include "clad/types/robotStatusAndActions.clad"
#include "clad/types/imageTypes.clad"
#include "clad/types/objectTypes.clad"
#include "clad/types/objectFamilies.clad"
#include "clad/types/proxMessages.clad"
#include "clad/types/powerMessages.clad"
#include "clad/types/debugConsoleTypes.clad"
#include "clad/externalInterface/messageShared.clad"
#include "clad/externalInterface/keyWordRecognized.clad"
#include "clad/robotInterface/messageFromActiveObject.clad"
#include "clad/audio/audioCallbackMessage.clad"

namespace Anki {
namespace Cozmo {
namespace ExternalInterface {

///////////////////////////////////////////////////////////////////////////////
////////////////////////  ADVERTISING & CONNECTING  ///////////////////////////
///////////////////////////////////////////////////////////////////////////////


// Let the UI know that a robot is advertising as available
message RobotAvailable {
    uint_32 robotID
}

message UiDeviceAvailable {
    uint_32 deviceID
}

message RobotConnected {
    uint_32 robotID,
    uint_8 successful
}

message RobotDisconnected {
    uint_32 robotID,
    float_32 timeSinceLastMsg_sec
}


message UiDeviceConnected {
    uint_32 deviceID,
    uint_8 successful
}

/*
message Bogus {
}
*/


///////////////////////////////////////////////////////////////////////////////
/////////////////////////////  ROBOT STATE  ///////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

message RobotState {
    float_32 pose_x,
    float_32 pose_y,
    float_32 pose_z,
    float_32 poseAngle_rad,    // heading in X-Y plane
    float_32 posePitch_rad,    // robot pitch angle
    float_32 pose_qw,          // full 3d rotation as a quaternion
    float_32 pose_qx,          //  "
    float_32 pose_qy,          //  "
    float_32 pose_qz,          //  "
    float_32 leftWheelSpeed_mmps,
    float_32 rightWheelSpeed_mmps,
    float_32 headAngle_rad,
    float_32 liftHeight_mm,
    float_32 batteryVoltage,
    int_32   carryingObjectID,      // will be -1 if not carrying object
    int_32   carryingObjectOnTopID, // will be -1 if no object on top of object being carried
    int_32   headTrackingObjectID,  // will be -1 if head is not tracking to any object
    int_32   localizedToObjectID,   // Will be -1 if not localized to any object
    uint_32  lastImageTimeStamp,    // Last image processed by the vision system
    uint_16  status,                // See RobotStatusFlag in cozmoTypes.h
    uint_8   gameStatus,            // See GameStatusFlag in cozmoTypes.h
    uint_8   robotID
}

message RobotPickedUp {
    uint_8   robotID
}

message RobotPutDown {
    uint_8   robotID
}

message RobotPoked {
    uint_8   robotID
}

// Generic string for sending debug string up to game
message DebugString {
    string    text
}


///////////////////////////////////////////////////////////////////////////////
/////////////////////////////////  VISION  ////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
/*
// Full QVGA Image from a specifed Robot
message RobotImage_320x240 {
    uint_32 robotID
    uint_8 image[320*240]
}

// Full VGA Image from a specifed Robot
message RobotImage_640x480 {
    uint_32 robotID
    uint_8 image[640*480]
}
*/

// RobotObservedObject for signaling that an object
//  with specified ID/Type/Family was seen at a particular location in the image
//  and the world
message RobotObservedObject {
    uint_32 robotID,
    uint_32 timestamp,
    ObjectFamily objectFamily,
    ObjectType   objectType,
    int_32  objectID,        // signed to match U2G::PickAndPlaceObject which has the option to have objectID<0
    float_32 img_topLeft_x,  // position in image coords
    float_32 img_topLeft_y,  //     "
    float_32 img_width,      //     "
    float_32 img_height,     //     "
    float_32 world_x,        // absolute 3D position in world coords
    float_32 world_y,        //     "
    float_32 world_z,        //     "
    float_32 quaternion_w,   // quaternion for 3D rotation (4 elements)
    float_32 quaternion_x,   //     "
    float_32 quaternion_y,   //     "
    float_32 quaternion_z,   //     "
    float_32 topFaceOrientation_rad, // absolute orienation of top face, iff isActive==true
    uint_8   markersVisible, // Observed via markers vs. "should" be visible based on previous observation
    uint_8   isActive
}

// RobotObservedFace
message RobotObservedFace {
    int_32   faceID,         // negative: tracked but not recognized; positive: recognized face
    uint_32  robotID,
    uint_32  timestamp,
    float_32 world_x,        // absolute 3D position in world coords
    float_32 world_y,        //     "
    float_32 world_z,        //     "
    float_32 quaternion_w,   // quaternion for 3D rotation (4 elements)
    float_32 quaternion_x,   //     "
    float_32 quaternion_y,   //     "
    float_32 quaternion_z,   //     "
// TODO: Add expression / landmark locations
}

// RobotChangedObservedFaceID
//  This generally happens when a tracked face (negative ID) is enrolled as a
//  face to be recognized (positive ID)
message RobotChangedObservedFaceID {
    int_32   oldID,
    int_32   newID
}

// RobotObservedMotion
message RobotObservedMotion {
    uint_32  timestamp, // Of the corresponding image
    float_32 img_area,  // Size of the region of detected motion, as a fraction of image
    int_16   img_x,     // Centroid of the motion region relative to image center, in pixels
    int_16   img_y,
    float_32 ground_area, // Amount of motion on the ground, as a fraction of the ground ROI (0 if none)
    int_16   ground_x,    // Centroid of the motion on the ground in robot coordinates, in mm
    int_16   ground_y
}

// RobotDeletedFace
message RobotDeletedFace {
    int_32  faceID,
    uint_32 robotID
}

// RobotObservedNothing
message RobotObservedNothing {
    uint_32 robotID
}

// RobotDeletedObject
message RobotDeletedObject {
    uint_32 robotID,
    uint_32 objectID
}

// DeviceDetectedVisionMarker
message DeviceDetectedVisionMarker {
    uint_32 markerType,
    float_32 x_upperLeft,
    float_32 y_upperLeft,
    float_32 x_lowerLeft,
    float_32 y_lowerLeft,
    float_32 x_upperRight,
    float_32 y_upperRight,
    float_32 x_lowerRight,
    float_32 y_lowerRight
}

// RobotMarkedObjectPoseUnknown
message RobotMarkedObjectPoseUnknown {
    uint_32 robotID,
    uint_32 objectID
}


///////////////////////////////////////////////////////////////////////////////
//////////////////////////////////  ACTIONS  //////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

// RobotCompletedAction
// TODO: Add action type, more informative result codes...
message RobotCompletedAction {
    uint_32 robotID,
    uint_32 idTag,                        // The identifier of the specific action that completed
    RobotActionType  actionType,          // see enum in actionTypes.def
    ActionResult  result,                 //  "
    ActionCompletedUnion completionInfo   //  "
}

// BlockPickedUp
message BlockPickedUp {
    bool didSucceed                       // true if robot thinks it picked up a block (from low or high position)
}

// BlockPlaced
message BlockPlaced {
    bool didSucceed                       // true if robot thinks it placed up a block (from low or high position)
}

///////////////////////////////////////////////////////////////////////////////
//////////////////////////////////  SOUND  ////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

// Note: these should go away when the robot can play its own sounds and doesn't
//       rely on the phone to do it.

message PlaySound {
    string soundFilename,
    uint_8 numLoops,
    uint_8 volume
}

message StopSound {
}

///////////////////////////////////////////////////////////////////////////////
///////////////////////////////  ANIMATIONS  //////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

message AnimationAvailable {
  string animName
}

// Broadcast by AnimationStreamer when a new streaming animation is requested
// before the last one finished.
message AnimationAborted {
  uint_32 tag
}

///////////////////////////////////////////////////////////////////////////////
// Mood / Emotions
///////////////////////////////////////////////////////////////////////////////

message MoodState {
  uint_8  robotID,
  float_32 emotionValues[uint_8]
}

///////////////////////////////////////////////////////////////////////////////
// Progression / Stats
///////////////////////////////////////////////////////////////////////////////

message ProgressionStats {
  uint_8  robotID,
  int_32 statValues[uint_8]
}

///////////////////////////////////////////////////////////////////////////////
// Debug / Console
///////////////////////////////////////////////////////////////////////////////

structure DebugConsoleVar {
  string varName,
  string category,
  float_32 minValue,
  float_32 maxValue,
  ConsoleVarUnion varValue
}


message InitDebugConsoleVarMessage {
  DebugConsoleVar varData[uint_8]
}
message VerifyDebugConsoleVarMessage {
  string varName,
  string statusMessage,
  ConsoleVarUnion varValue
}

///////////////////////////////////////////////////////////////////////////////
//////////////////////////////////  GAME  /////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

// The behavior wants the UI to pop up a game request
message RequestGameStart {}

// keep empty to generate an auto-union that includes all messages in this file
// if you do not want to include messages in this union, use the keyword "structure" instead of "message"
union MessageEngineToGame { }

} // namespace G2U
} // namespace Cozmo
} // namespace Anki
