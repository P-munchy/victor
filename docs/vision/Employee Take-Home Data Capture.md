# Employee Take-Home Data Capture
Created by Andrew Stein Last updated Oct 19, 2018

## Instructions
Step 1: Place Vector on plugged in charger at home

Step 2: Turn on your robot by pressing the button if he doesn't automatically turn on when being placed on charger

Step 3: Vector will start in a special mode showing his camera feed on his face (If using your own Dev robot, use WebViz to select the "DevImageCapture_PetsAndHands" behavior; Just make sure you have latest master build on your robot!)

Step 4: At the top of his screen, in yellow text, you’ll see which “category” of images he’s set to capture, and how many images he currently has of that category. It should start at zero (e.g. “Cats: 0”). To cycle through the list of categories, raise and and lower his lift. You’ll see the current category change on his screen.

Step 5: Choose desired category and put Vector in a setting/position to see something in the selected category (NOTE: it is safe to move his head manually up and down!). To take a picture of desired image, press his backpack button. You will hear a series of shutter noises and see Vector move as he takes 5 images in slightly different positions. When he finishes, you’ll also see the count on his screen has increased by 5. Repeat as many times as you can to get a variety of images for the selected category.

Step 6: Use the lift to scroll through to another desired category. Repeat step 5 and take more captures.

Step 7: For all applicable categories (Hands, Cats and Dogs, People, Background) please try to take at least 10 captures (10 button pushes = 50 total images per category). The more the better!

Step 8: Return robot and charger to Megan (MB) the next day. (If you are using your own Dev robot, you can bring it directly to Andrew or Rob.)


## Instruction Videos: (Large | Small)

## Category Specifics

### Hands:

In natural poses on or near the table (We are not looking for hand gestures in the air at this time)

We are initially training a system just to report whether or not a hand is present right in front of the robot, so it should fill a significant portion of the camera’s field of view.

Hands interacting with things like a cup, a keyboard/mouse, or a remote are fair game

### Cats/Dogs:

Like hands, we are initially only working to determine presence/absence of a pet (not where it is in the image), so whole pets or significant portions of them should occupy most of the field of view. (Vector should be within a foot or two of the pet, depending on the pet’s relative size.)

Faces are great, but so are side/rear views. Or animals curled up in balls.

Looking down from a table/counter as well as being on the same level (i.e. the floor) with the pet.

### People:

Here we are also trying to detect where the person is in the image, so they can be near or far, with or without face visible. (E.g. torso only, or side/back views.)

May be easier with a helper who can push the button for you.

### “Backgrounds”:

These are images not containing any of the above, and are disproportionately important and helpful, even if not obvious!

A variety of settings, viewpoints, times of day, and room types

Just turning the robot in place to see a different part of the room is a very different image, so it should be quick to get lots of these even from one position.

House plants could potentially be confusing objects for the vision system, so images of those could be great to have in the “background” category.

## Category Examples
These are examples of good images of each category we want for employee take-home data capture.

### Pets
### Hands
### People
### Background


